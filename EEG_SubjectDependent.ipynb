{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Collegamento Google Drive**"
      ],
      "metadata": {
        "id": "DxoL219icBu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "C96FHlUUDlRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86165087-c5d7-418e-81d9-fbc32ce9e83a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH3rDLJEZKXh"
      },
      "source": [
        "# **Valutazione Modelli**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import librerie**"
      ],
      "metadata": {
        "id": "bh3uNvfq-OJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#modelli\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import normalize"
      ],
      "metadata": {
        "id": "xJVoNbOKB7iA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dati"
      ],
      "metadata": {
        "id": "uRYA4G-8fruZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import dati\n",
        "data_combined = pd.read_csv('/content/drive/Shareddrives/biometria_progetto/combinated_data.csv')\n",
        "keystotal = data_combined['Key']\n",
        "data_combined2 = data_combined.drop(['Key'], axis=1)\n",
        "\n",
        "#rimozione dei valori nulli\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "dati_imputed = pd.DataFrame(imputer.fit_transform(data_combined2), columns=data_combined2.columns)\n",
        "\n",
        "#normalizzazione dei dati\n",
        "normalised_data = pd.DataFrame(normalize(dati_imputed, axis = 0))\n",
        "normalised_data['Key']= keystotal\n",
        "dati_imputed['Key']= keystotal"
      ],
      "metadata": {
        "id": "n_tBN148rGtd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbOXO4ZgoA-h"
      },
      "source": [
        "# **MAIN** (Subject dependent)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caricamento delle etichette da un file CSV\n",
        "etichette_train =pd.read_csv('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectIndipendent/etichettetrain.csv')\n",
        "etichette_test = pd.read_csv('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectIndipendent/etichettetest.csv')\n",
        "\n",
        "# Lista dei partecipanti\n",
        "lista_partecipanti = [\"ldy\", \"rx\", \"qyt\", \"tyc\", \"ha\", \"whh\", \"mz\", \"mhw\", \"zjy\", \"wll\" ,\"zjd\", \"hql\", \"ly\", \"wq\", \"cz\"]"
      ],
      "metadata": {
        "id": "QD1Lr_j46gvO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Funzione split randomico**"
      ],
      "metadata": {
        "id": "qsGgWKYZzZU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#siccome il set di dati Ã¨ piccolo questa funzione mi garantisce che nella selezione randomica dei segnali ci siano 2 elementi di ogni classe per i dati di test\n",
        "def divide_train_test(data, labels):\n",
        "    classes = np.unique(labels)\n",
        "    train_data = []\n",
        "    train_labels = []\n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "\n",
        "    for cls in classes:\n",
        "        class_indices = np.where(labels == cls)[0]\n",
        "        np.random.shuffle(class_indices)\n",
        "\n",
        "        test_indices = class_indices[:2]\n",
        "        train_indices = class_indices[2:]\n",
        "\n",
        "        test_data.extend(data[test_indices])\n",
        "        test_labels.extend(labels[test_indices])\n",
        "        train_data.extend(data[train_indices])\n",
        "        train_labels.extend(labels[train_indices])\n",
        "\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)"
      ],
      "metadata": {
        "id": "EZ-u71y4wduy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **XGBOOST**"
      ],
      "metadata": {
        "id": "aDbSDZD-x4ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_xgboost= 0.0\n",
        "media_xgboost= 0.0\n",
        "accuracyfinalxgboost= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    #prendiamo un solo partecipante \n",
        "    data_par= data[data['Key'].str.contains(partecipante)]\n",
        "    data_partecipant = data_par.drop(['Key'], axis=1)\n",
        "    X_train, y_train, X_test, y_test = divide_train_test(np.array(data_partecipant), np.array(etichette_test))\n",
        "\n",
        "    # Importa il modello migliore \n",
        "    best_xgboost_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_xgboost_model.pkl\")\n",
        "  \n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_xgboost_model.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "    xgboost_pred = best_xgboost_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_xgboost = accuracy_score(y_test, xgboost_pred)\n",
        "  \n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_xgboost += accuracy_xgboost\n",
        "      \n",
        "  # Calcolo della media per sessione\n",
        "  media_xgboost = acc_xgboost / 15\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalxgboost += media_xgboost\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza XGBOOST:\", accuracyfinalxgboost/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTbu9UvK61Kb",
        "outputId": "ea140b28-64b4-457b-8d1e-ae4bc7e3a97a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza XGBOOST: 0.7805555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SVM**"
      ],
      "metadata": {
        "id": "-b3nf9iByoLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_svm= 0.0\n",
        "media_svm= 0.0\n",
        "accuracyfinalvsm= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    #prendiamo un solo partecipante \n",
        "    data_par= data[data['Key'].str.contains(partecipante)]\n",
        "    data_partecipant = data_par.drop(['Key'], axis=1)\n",
        "    X_train, y_train, X_test, y_test = divide_train_test(np.array(data_partecipant), np.array(etichette_test))\n",
        "\n",
        "    # Importa il modello migliore \n",
        "    best_svm_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_svm_model.pkl\")\n",
        "\n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_svm_model.fit(X_train,np.ravel(y_train))\n",
        "\n",
        "    svm_pred= best_svm_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_svm = accuracy_score(y_test, svm_pred)\n",
        "  \n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_svm += accuracy_svm\n",
        "      \n",
        "  # Calcolo della media per sessione\n",
        "  media_svm = acc_svm / 15\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalvsm += media_svm\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza SMV:\", accuracyfinalvsm/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M38vvKD7TMH",
        "outputId": "ab74bbea-7073-4a9c-8b8d-ef82c49056ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza SMV: 0.6166666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest**"
      ],
      "metadata": {
        "id": "sX8cLub-z5Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_rf= 0.0\n",
        "media_rf= 0.0\n",
        "accuracyfinalrf= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    #prendiamo un solo partecipante \n",
        "    data_par= data[data['Key'].str.contains(partecipante)]\n",
        "    data_partecipant = data_par.drop(['Key'], axis=1)\n",
        "    X_train, y_train, X_test, y_test = divide_train_test(np.array(data_partecipant), np.array(etichette_test))\n",
        "\n",
        "    # Importa il modello migliore \n",
        "    best_rf_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_rf_model.pkl\")\n",
        "\n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_rf_model.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "    rf_pred=best_rf_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_rf = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_rf += accuracy_rf\n",
        "      \n",
        "  # Calcolo della media per sessione\n",
        "  media_rf = acc_rf / 15\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalrf +=media_rf\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza Random Forest:\", accuracyfinalrf/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6QKsAPG7mPS",
        "outputId": "30a539f4-973b-4b21-9be0-79dc7c6e982c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza Random Forest: 0.5527777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Logistic Regression**"
      ],
      "metadata": {
        "id": "mqCfYvsBz-bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_lr= 0.0\n",
        "media_lr= 0.0\n",
        "accuracyfinallr= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=dati_imputed[dati_imputed['Key'].str.contains(f\"{i}_\")]\n",
        "    #prendiamo un solo partecipante \n",
        "    data_par= data[data['Key'].str.contains(partecipante)]\n",
        "    data_partecipant = data_par.drop(['Key'], axis=1)\n",
        "    X_train, y_train, X_test, y_test = divide_train_test(np.array(data_partecipant), np.array(etichette_test))\n",
        "\n",
        "    # Importa il modello migliore \n",
        "    best_lr_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_lr_model.pkl\")\n",
        "\n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_lr_model.fit(X_train,np.ravel(y_train))\n",
        "\n",
        "    lr_pred=best_lr_model.predict(X_test)\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_lr = accuracy_score(y_test, lr_pred)\n",
        "\n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_lr += accuracy_lr\n",
        "      \n",
        "  #Calcolo della media per sessione\n",
        "  media_lr = acc_lr / 15\n",
        "\n",
        "  #Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinallr +=media_lr\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza Logistic Regression:\", accuracyfinallr/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhcUMzWS7tqQ",
        "outputId": "a7c1b5cc-7714-4b93-b9b1-b0d14b5c2f13"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza Logistic Regression: 0.6277777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Naive Bayes**"
      ],
      "metadata": {
        "id": "3XQ7u5zx0nIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_nb= 0.0\n",
        "media_nb= 0.0\n",
        "accuracyfinalnb= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    #prendiamo un solo partecipante \n",
        "    data_par= data[data['Key'].str.contains(partecipante)]\n",
        "    data_partecipant = data_par.drop(['Key'], axis=1)\n",
        "    X_train, y_train, X_test, y_test = divide_train_test(np.array(data_partecipant), np.array(etichette_test))\n",
        "\n",
        "    # Importa il modello migliore \n",
        "    best_nb_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_nb_model.pkl\")\n",
        "\n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_nb_model.fit(X_train,np.ravel(y_train))\n",
        "\n",
        "    nb_pred=best_nb_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_nb = accuracy_score(y_test, nb_pred)\n",
        "\n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_nb += accuracy_nb\n",
        "      \n",
        "  # Calcolo della media per sessione\n",
        "  media_nb = acc_nb / 15\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalnb +=media_nb\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza Naive Bayes:\", accuracyfinalnb/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrES-EEJ8aSJ",
        "outputId": "5210a861-eee8-4df0-84d0-538c4f76294c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza Naive Bayes: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **AdaBoost**"
      ],
      "metadata": {
        "id": "yPBJJ4oF1ciX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_ab = 0.0\n",
        "media_ab  =0.0\n",
        "accuracyfinalab=0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    #prendiamo un solo partecipante \n",
        "    data_par= data[data['Key'].str.contains(partecipante)]\n",
        "    data_partecipant = data_par.drop(['Key'], axis=1)\n",
        "    X_train, y_train, X_test, y_test = divide_train_test(np.array(data_partecipant), np.array(etichette_test))\n",
        "\n",
        "    # Importa il modello migliore \n",
        "    best_ab_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_adaboost_model.pkl\")\n",
        "\n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_ab_model.fit(X_train,np.ravel(y_train))\n",
        "\n",
        "    ab_pred=best_nb_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_ab = accuracy_score(y_test, nb_pred)\n",
        "  \n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_ab += accuracy_ab\n",
        "      \n",
        "  # Calcolo della media per sessione\n",
        "  media_ab = acc_ab / 15\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalab +=media_ab\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza AdaBoost:\", accuracyfinalab/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZbHxnIF6fuQ",
        "outputId": "3d9b0ff1-d4b5-4dce-f353-cfe83a94700d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza AdaBoost: 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Codice completo con tutti e 6 i modelli**"
      ],
      "metadata": {
        "id": "Qy0uDWdJyFZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_xgboost,acc_svm,acc_rf,acc_lr, acc_nb,acc_ab = 0.0,0.0,0.0,0.0,0.0,0.0\n",
        "media_xgboost,media_svm,media_rf,media_lr,media_nb,media_ab  =0.0,0.0,0.0,0.0,0.0,0.0\n",
        "accuracyfinalxgboost,accuracyfinalvsm,accuracyfinalrf,accuracyfinallr,accuracyfinalnb,accuracyfinalab =0.0,0.0,0.0,0.0,0.0,0.0\n",
        "\n",
        "# Lista dei partecipanti\n",
        "lista_partecipanti = [\"ldy\", \"rx\", \"qyt\", \"tyc\", \"ha\", \"whh\", \"mz\", \"mhw\", \"zjy\", \"wll\" ,\"zjd\", \"hql\", \"ly\", \"wq\", \"cz\"]\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=data_eeg[data_eeg['Key'].str.contains(f\"{i}_\")]\n",
        "    #prendiamo un solo partecipante \n",
        "    data_par= data[data['Key'].str.contains(partecipante)]\n",
        "    data_partecipant = data_par.drop(['Key'], axis=1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_partecipant, etichette_test, test_size=0.33, random_state=42)\n",
        "\n",
        "    # Importa il modello migliore \n",
        "    best_xgboost_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_xgboost_model.pkl\")\n",
        "    best_svm_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_svm_model.pkl\")\n",
        "    best_rf_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_rf_model.pkl\")\n",
        "    best_lr_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_lr_model.pkl\")\n",
        "    best_nb_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_nb_model.pkl\")\n",
        "    best_ab_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_adaboost_model.pkl\")\n",
        "\n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_xgboost_model.fit(X_train, np.ravel(y_train))\n",
        "    best_svm_model.fit(X_train,np.ravel(y_train))\n",
        "    best_rf_model.fit(X_train, np.ravel(y_train))\n",
        "    best_lr_model.fit(X_train,np.ravel(y_train))\n",
        "    best_nb_model.fit(X_train,np.ravel(y_train))\n",
        "    best_ab_model.fit(X_train,np.ravel(y_train))\n",
        "\n",
        "    xgboost_pred = best_xgboost_model.predict(X_test)\n",
        "    svm_pred= best_svm_model.predict(X_test)\n",
        "    rf_pred=best_rf_model.predict(X_test)\n",
        "    lr_pred=best_lr_model.predict(X_test)\n",
        "    nb_pred=best_nb_model.predict(X_test)\n",
        "    ab_pred=best_nb_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_xgboost = accuracy_score(y_test, xgboost_pred)\n",
        "    accuracy_svm = accuracy_score(y_test, svm_pred)\n",
        "    accuracy_rf = accuracy_score(y_test, rf_pred)\n",
        "    accuracy_lr = accuracy_score(y_test, lr_pred)\n",
        "    accuracy_nb = accuracy_score(y_test, nb_pred)\n",
        "    accuracy_ab = accuracy_score(y_test, nb_pred)\n",
        "  \n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_xgboost += accuracy_xgboost\n",
        "    acc_svm += accuracy_svm\n",
        "    acc_rf += accuracy_rf\n",
        "    acc_lr += accuracy_lr\n",
        "    acc_nb += accuracy_nb\n",
        "    acc_ab += accuracy_ab\n",
        "      \n",
        "  # Calcolo della media per sessione\n",
        "  media_xgboost = acc_xgboost / 15\n",
        "  media_svm = acc_svm / 15\n",
        "  media_rf = acc_rf / 15\n",
        "  media_lr = acc_lr / 15\n",
        "  media_nb = acc_nb / 15\n",
        "  media_ab = acc_ab / 15\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalxgboost += media_xgboost\n",
        "  accuracyfinalvsm += media_svm\n",
        "  accuracyfinalrf +=media_rf\n",
        "  accuracyfinallr +=media_lr\n",
        "  accuracyfinalnb +=media_nb\n",
        "  accuracyfinalab +=media_ab\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza XGBOOST:\", accuracyfinalxgboost/3)\n",
        "print(\"Media dell'accuratezza SMV:\", accuracyfinalvsm/3)\n",
        "print(\"Media dell'accuratezza RF:\", accuracyfinalrf/3)\n",
        "print(\"Media dell'accuratezza LR:\", accuracyfinallr/3)\n",
        "print(\"Media dell'accuratezza NB:\", accuracyfinalnb/3)\n",
        "print(\"Media dell'accuratezza AB:\", accuracyfinalab/3)'''"
      ],
      "metadata": {
        "id": "3zeJSo-N4KTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Requirements**"
      ],
      "metadata": {
        "id": "nrXJWa_4yj8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Comando necessario per ottenere le librerie installate insieme alle loro versioni specifiche.\n",
        "import subprocess\n",
        "path = '/content/drive/Shareddrives/biometria_progetto/requirements_SD.txt'\n",
        "subprocess.run(f'pip freeze > {path}', shell=True, check=True)"
      ],
      "metadata": {
        "id": "4HQOHSG5ynyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504aea3f-c65e-4ee6-8121-28c83fd23f77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='pip freeze > /content/drive/Shareddrives/biometria_progetto/requirements_SD.txt', returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}