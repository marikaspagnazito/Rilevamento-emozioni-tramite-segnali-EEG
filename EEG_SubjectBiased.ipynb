{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Collegamento Google Drive**"
      ],
      "metadata": {
        "id": "DxoL219icBu1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trmqYQ5CoNcP",
        "outputId": "cfc37fef-68dc-4b08-c5fe-c8af926a54c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH3rDLJEZKXh"
      },
      "source": [
        "# **Valutazione Modelli**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import librerie**"
      ],
      "metadata": {
        "id": "bh3uNvfq-OJx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N8UEcqngncq9"
      },
      "outputs": [],
      "source": [
        "#utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#modelli\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Install Optuna*"
      ],
      "metadata": {
        "id": "VmZ5_CGccboN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1Wcb9UMOne17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa89e2d5-9525-417b-a273-3d1093fb8b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y_VHmS62LR7"
      },
      "source": [
        "# **PROTOCOLLO SUBJECT BIASED** (split randomico 70/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vABoHDB9vE8R"
      },
      "outputs": [],
      "source": [
        "# Carico il dataset\n",
        "\n",
        "#import dati combinati\n",
        "data_combined = pd.read_csv('/content/drive/Shareddrives/biometria_progetto/combinated_data.csv')\n",
        "data_combined2 = data_combined.drop(['Key'], axis=1)\n",
        "\n",
        "#elimino i valori NAN\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "dati_imputed = pd.DataFrame(imputer.fit_transform(data_combined2), columns=data_combined2.columns)\n",
        "\n",
        "#normalizzazione dei dati\n",
        "normalised_data = pd.DataFrame(normalize(dati_imputed, axis = 0))\n",
        "\n",
        "# Caricamento delle etichette da un file CSV\n",
        "etichette_df = pd.read_csv('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/etichette.csv')\n",
        "\n",
        "# Estrazione delle etichette dal dataframe\n",
        "etichette = etichette_df.iloc[:, 0].values\n",
        "\n",
        "# Divisione dei dati in set di addestramento e test randomico secondo la regola 70/30\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalised_data, etichette, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRtBL9mD1s4e"
      },
      "source": [
        "# **Definizione funzioni obiettivo per l'ottimizzazione di Optuna** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I45c-62Dnoeh"
      },
      "source": [
        "# **XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dAB_swwYnrZ7"
      },
      "outputs": [],
      "source": [
        "# Verifica se la GPU è disponibile\n",
        "USE_GPU = xgb.__version__.endswith('gpu')\n",
        "\n",
        "# Definisci la funzione obiettivo per l'ottimizzazione di Optuna\n",
        "def xgboost_objective(trial):\n",
        "    # Parametri da ottimizzare per XGBoost\n",
        "\n",
        "    params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'logloss',\n",
        "        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
        "        'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.00001, 0.1, log=True),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
        "        'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 10.0),\n",
        "        'tree_method': 'gpu_hist' if USE_GPU else 'auto',\n",
        "        'n_jobs': -1,\n",
        "        'verbosity': 0,\n",
        "    }\n",
        "\n",
        "\n",
        "    # Creazione del classificatore XGBoost con i parametri ottimizzati\n",
        "    xgb_classifier = xgb.XGBClassifier(**params)\n",
        "\n",
        "    # Addestramento del modello\n",
        "    xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Valutazione sul set di test\n",
        "    y_pred = xgb_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Salva i risultati dell'esecuzione corrente\n",
        "    trial.set_user_attr(\"params\", params)\n",
        "    trial.set_user_attr(\"accuracy\", accuracy)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUbZv7stnuz7"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wr2EZFhHnuhr"
      },
      "outputs": [],
      "source": [
        "# Definisci la funzione obiettivo per l'ottimizzazione di Optuna per SVM\n",
        "def svm_objective(trial):\n",
        "    # Definizione degli iperparametri da ottimizzare\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 1e-6, 1e+6, log=True),\n",
        "        'kernel': trial.suggest_categorical('kernel', ['sigmoid']),\n",
        "        'degree': trial.suggest_int('degree', 1, 2),\n",
        "        'gamma': trial.suggest_float('gamma', 1e-6, 1e+1, log=True),\n",
        "        'coef0': trial.suggest_float('coef0', -1.0, 1.0),\n",
        "    }\n",
        "\n",
        "\n",
        "    # Creazione del classificatore SVM con i parametri ottimizzati\n",
        "    svm_classifier = SVC(**params)\n",
        "\n",
        "    # Addestramento del modello\n",
        "    svm_classifier.fit(X_train,  np.ravel(y_train))\n",
        "\n",
        "    # Valutazione sul set di test\n",
        "    y_pred = svm_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Salva i risultati dell'esecuzione corrente\n",
        "    trial.set_user_attr(\"params\", params)\n",
        "    trial.set_user_attr(\"accuracy\", accuracy)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM03s4wQnzSc"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPcYDBPmn1PM"
      },
      "outputs": [],
      "source": [
        "# Definisci la funzione obiettivo per l'ottimizzazione di Optuna per Random Forest\n",
        "def rf_objective(trial):\n",
        "    # Parametri da ottimizzare per Random Forest\n",
        "    \n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n",
        "        'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
        "    }\n",
        "\n",
        "    # Creazione del classificatore Random Forest con i parametri ottimizzati\n",
        "    rf_classifier = RandomForestClassifier(**params)\n",
        "\n",
        "    # Addestramento del modello\n",
        "    rf_classifier.fit(X_train,  np.ravel(y_train))\n",
        "    # Valutazione sul set di test\n",
        "    y_pred = rf_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Salva i risultati dell'esecuzione corrente\n",
        "    trial.set_user_attr(\"params\", params)\n",
        "    trial.set_user_attr(\"accuracy\", accuracy)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression**"
      ],
      "metadata": {
        "id": "T1dx1a3aswh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisci la funzione obiettivo per l'ottimizzazione di Optuna per Logistic Regression\n",
        "def lr_objective(trial):\n",
        "    # Parametri da ottimizzare per Logistic Regression\n",
        "    params = {\n",
        "        'C': trial.suggest_loguniform('C', 0.001, 100),\n",
        "        'solver': trial.suggest_categorical('solver', ['liblinear', 'saga']),\n",
        "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "        'max_iter': trial.suggest_int('max_iter', 100, 1000, step=100),\n",
        "    }\n",
        "\n",
        "    # Creazione del classificatore Logistic Regression con i parametri ottimizzati\n",
        "    lr_classifier = LogisticRegression(**params)\n",
        "\n",
        "    # Addestramento del modello\n",
        "    lr_classifier.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "    # Valutazione sul set di test\n",
        "    y_pred = lr_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Salva i risultati dell'esecuzione corrente\n",
        "    trial.set_user_attr(\"params\", params)\n",
        "    trial.set_user_attr(\"accuracy\", accuracy)\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "-TH2QoDwszHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes**"
      ],
      "metadata": {
        "id": "Mf7QpvjOs7D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisci la funzione obiettivo per l'ottimizzazione di Optuna per Naive Bayes\n",
        "def nb_objective(trial):\n",
        "    # Parametri da ottimizzare per Naive Bayes\n",
        "    params = {\n",
        "        'var_smoothing': trial.suggest_loguniform('var_smoothing', 1e-10, 1e-1),\n",
        "    }\n",
        "\n",
        "    # Creazione del classificatore Naive Bayes con i parametri ottimizzati\n",
        "    nb_classifier = GaussianNB(**params)\n",
        "\n",
        "    # Addestramento del modello\n",
        "    nb_classifier.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "    # Valutazione sul set di test\n",
        "    y_pred = nb_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Salva i risultati dell'esecuzione corrente\n",
        "    trial.set_user_attr(\"params\", params)\n",
        "    trial.set_user_attr(\"accuracy\", accuracy)\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "_xg_3L79tDrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AdaBoost**"
      ],
      "metadata": {
        "id": "0wcbUdvB1pCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisci la funzione obiettivo per l'ottimizzazione di Optuna\n",
        "def adaboost_objective(trial):\n",
        "    # Parametri da ottimizzare per AdaBoost\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
        "        'algorithm': trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R']),\n",
        "        # Aggiungi altri parametri se necessario\n",
        "    }\n",
        "\n",
        "    # Creazione del classificatore AdaBoost con i parametri ottimizzati\n",
        "    adaboost_classifier = AdaBoostClassifier(**params)\n",
        "\n",
        "    # Addestramento del modello\n",
        "    adaboost_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Valutazione sul set di test\n",
        "    y_pred = adaboost_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Salva i risultati dell'esecuzione corrente\n",
        "    trial.set_user_attr(\"params\", params)\n",
        "    trial.set_user_attr(\"accuracy\", accuracy)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "2C266LhS1fst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbOXO4ZgoA-h"
      },
      "source": [
        "# **SEARCH BEST MODEL**\n",
        "Effettuiamo 50 iterazioni per ottenere il miglior modello (n_trials=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **XGBoost**"
      ],
      "metadata": {
        "id": "Dgyy3m4PcsRP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gidUAN0ZwZq3"
      },
      "outputs": [],
      "source": [
        "# Creazione dello studio Optuna per XGBoost\n",
        "xgboost_study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Esecuzione dell'ottimizzazione dei parametri per XGBoost\n",
        "xgboost_study.optimize(xgboost_objective, n_trials=50)\n",
        "\n",
        "# Dopo aver eseguito l'ottimizzazione dei parametri\n",
        "best_trial = xgboost_study.best_trial\n",
        "\n",
        "# Ottenere i migliori parametri per il modello XGBoost\n",
        "best_params = best_trial.params\n",
        "\n",
        "# Creazione del modello XGBoost con i migliori parametri\n",
        "best_xgboost_model = xgb.XGBClassifier(**best_params)\n",
        "\n",
        "# Addestramento del modello con tutti i dati di addestramento\n",
        "best_xgboost_model.fit(X_train, y_train)\n",
        "\n",
        "# Salvare il miglior modello ottenuto per XGBoost\n",
        "joblib.dump(best_xgboost_model, \"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_xgboost_model.pkl\")\n",
        "\n",
        "# Salvataggio dei risultati in un DataFrame per XGBoost\n",
        "xgboost_results = pd.DataFrame(xgboost_study.trials)\n",
        "xgboost_results.to_csv(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/xgboost_optuna_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SVM**"
      ],
      "metadata": {
        "id": "hm78IN_jc1al"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqxPfrMhwx7F"
      },
      "outputs": [],
      "source": [
        "# Creazione dello studio Optuna per SVM\n",
        "svm_study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Esecuzione dell'ottimizzazione dei parametri per SVM\n",
        "svm_study.optimize(svm_objective, n_trials=50)\n",
        "\n",
        "# Dopo aver eseguito l'ottimizzazione dei parametri\n",
        "best_trial = svm_study.best_trial\n",
        "\n",
        "# Ottenere i migliori parametri per il modello SVM\n",
        "best_params = best_trial.params\n",
        "\n",
        "# Creazione del modello SVM con i migliori parametri\n",
        "best_svm_model = SVC(**best_params)\n",
        "\n",
        "# Addestramento del modello con tutti i dati di addestramento\n",
        "best_svm_model.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "# Salvare il miglior modello ottenuto per SVM\n",
        "joblib.dump(best_svm_model, \"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_svm_model.pkl\")\n",
        "\n",
        "# Salvataggio dei risultati in un DataFrame\n",
        "svm_results = pd.DataFrame(svm_study.trials)\n",
        "svm_results.to_csv(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/svm_optuna_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest**"
      ],
      "metadata": {
        "id": "XpIWzff-cxYU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCvFjeBIw0aq"
      },
      "outputs": [],
      "source": [
        "# Creazione dello studio Optuna per Random Forest\n",
        "rf_study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Esecuzione dell'ottimizzazione dei parametri\n",
        "rf_study.optimize(rf_objective, n_trials=50)\n",
        "\n",
        "# Dopo aver eseguito l'ottimizzazione dei parametri\n",
        "best_trial = rf_study.best_trial\n",
        "\n",
        "# Ottenere i migliori parametri per il modello Random Forest\n",
        "best_params = best_trial.params\n",
        "\n",
        "# Creazione del modello Random Forest con i migliori parametri\n",
        "best_rf_model = RandomForestClassifier(**best_params)\n",
        "\n",
        "# Addestramento del modello con tutti i dati di addestramento\n",
        "best_rf_model.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "# Salvare il miglior modello ottenuto per Random Forest\n",
        "joblib.dump(best_rf_model, \"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_rf_model.pkl\")\n",
        "\n",
        "# Salvataggio dei risultati in un DataFrame\n",
        "rf_results = pd.DataFrame(rf_study.trials)\n",
        "rf_results.to_csv(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/rf_optuna_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression**"
      ],
      "metadata": {
        "id": "84CS68BeqPxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Creazione dello studio Optuna per Logistic Regression\n",
        "lr_study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Esecuzione dell'ottimizzazione dei parametri per Logistic Regression\n",
        "lr_study.optimize(lr_objective, n_trials=50)\n",
        "\n",
        "# Dopo aver eseguito l'ottimizzazione dei parametri\n",
        "best_trial = lr_study.best_trial\n",
        "\n",
        "# Ottenere i migliori parametri per il modello Logistic Regression\n",
        "best_params = best_trial.params\n",
        "\n",
        "# Creazione del modello Logistic Regression con i migliori parametri\n",
        "best_lr_model = LogisticRegression(**best_params)\n",
        "\n",
        "# Addestramento del modello con tutti i dati di addestramento\n",
        "best_lr_model.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "# Salvare il miglior modello ottenuto per Logistic Regression\n",
        "joblib.dump(best_lr_model, \"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_lr_model.pkl\")\n",
        "\n",
        "# Salvataggio dei risultati in un DataFrame\n",
        "lr_results = pd.DataFrame(lr_study.trials)\n",
        "lr_results.to_csv(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/lr_optuna_results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "5oddQW2opyX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "-uNdeBAeq_w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Creazione dello studio Optuna per Naive Bayes Classifier\n",
        "nb_study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Esecuzione dell'ottimizzazione dei parametri per Naive Bayes Classifier\n",
        "nb_study.optimize(nb_objective, n_trials=50)\n",
        "\n",
        "# Dopo aver eseguito l'ottimizzazione dei parametri\n",
        "best_trial = nb_study.best_trial\n",
        "\n",
        "# Ottenere i migliori parametri per il modello Naive Bayes Classifier\n",
        "best_params = best_trial.params\n",
        "\n",
        "# Creazione del modello Naive Bayes Classifier con i migliori parametri\n",
        "best_nb_model = GaussianNB(**best_params)\n",
        "\n",
        "# Addestramento del modello con tutti i dati di addestramento\n",
        "best_nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Salvare il miglior modello ottenuto per Naive Bayes Classifier\n",
        "joblib.dump(best_nb_model, \"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_nb_model.pkl\")\n",
        "\n",
        "# Salvataggio dei risultati in un DataFrame\n",
        "nb_results = pd.DataFrame(nb_study.trials)\n",
        "nb_results.to_csv(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/nb_optuna_results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "2kefQ3XhroVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AdaBoost**"
      ],
      "metadata": {
        "id": "Du0AcjkR_CrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creazione dello studio Optuna per AdaBoost\n",
        "adaboost_study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Esecuzione dell'ottimizzazione dei parametri per AdaBoost\n",
        "adaboost_study.optimize(adaboost_objective, n_trials=50)\n",
        "\n",
        "# Dopo aver eseguito l'ottimizzazione dei parametri\n",
        "best_trial = adaboost_study.best_trial\n",
        "\n",
        "# Ottenere i migliori parametri per il modello AdaBoost\n",
        "best_params = best_trial.params\n",
        "\n",
        "# Creazione del modello AdaBoost con i migliori parametri\n",
        "best_adaboost_model = AdaBoostClassifier(**best_params)\n",
        "\n",
        "# Addestramento del modello con tutti i dati di addestramento\n",
        "best_adaboost_model.fit(X_train, y_train)\n",
        "\n",
        "# Salvare il miglior modello ottenuto per AdaBoost\n",
        "joblib.dump(best_adaboost_model, \"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_adaboost_model.pkl\")\n",
        "\n",
        "# Salvataggio dei risultati in un DataFrame per AdaBoost\n",
        "adaboost_results = pd.DataFrame(adaboost_study.trials)\n",
        "adaboost_results.to_csv(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/adaboost_optuna_results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "lqqLqtlsCwUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYP0NgZoSrLQ"
      },
      "source": [
        "# **EVALUATE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sVK4gVnASvth"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(X_test, y_test, model_name, model):\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # Calcolare la precisione, il richiamo e l'F1-score\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "        \n",
        "    # Crea un DataFrame con i risultati\n",
        "    results = pd.DataFrame({'Model': [model_name],\n",
        "                            'Accuracy': [accuracy],\n",
        "                            'Precision': [precision],\n",
        "                            'Recall': [recall],\n",
        "                            'F1-score': [f1]})\n",
        "    \n",
        "    # Salva i risultati in un file CSV\n",
        "    results.to_csv('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Metriche_modelli/'+model_name+'_metrics_results.csv', index=False)\n",
        "\n",
        "    # Calcolare la matrice di confusione normalizzata\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Creare una figura per la matrice di confusione\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Plotting della matrice di confusione normalizzata utilizzando una heatmap\n",
        "    sns.heatmap(cm_normalized, annot=True, cmap=plt.cm.Blues)\n",
        "\n",
        "    # Impostazione dei titoli degli assi\n",
        "    plt.title(model_name + ' Confusion Matrix')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "\n",
        "    # Salva la matrice di confusione come un file PDF\n",
        "    plt.savefig('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Matrici_di_confusione/' + model_name + '_confusion_matrix.pdf', format='pdf', bbox_inches='tight')\n",
        "\n",
        "    # Chiude la figura\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MAIN**"
      ],
      "metadata": {
        "id": "wQbJOdefB07Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBOOST\n",
        "#Importa il modello migliore \n",
        "best_xgboost_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_xgboost_model.pkl\")\n",
        "#Addestramento dei con tutti i dati di addestramento\n",
        "best_xgboost_model.fit(X_train, np.ravel(y_train))\n",
        "# Salva le metriche di valutazione del modello migliore di XGBoost\n",
        "evaluate_model(X_test, y_test, \"XGBoost\",best_xgboost_model)\n",
        "xgboost_pred = best_xgboost_model.predict(X_test)\n",
        "#Calcola le metriche per la classificazione\n",
        "accuracy_xgboost = accuracy_score(y_test, xgboost_pred)\n",
        "\n",
        "#SVM\n",
        "#Importa il modello migliore \n",
        "best_svm_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_svm_model.pkl\")\n",
        "# Addestramento dei con tutti i dati di addestramento\n",
        "best_svm_model.fit(X_train,np.ravel(y_train))\n",
        "# Salva le metriche di valutazione del modello migliore di SVM\n",
        "evaluate_model(X_test, y_test, \"SVM\", best_svm_model)\n",
        "svm_pred= best_svm_model.predict(X_test)\n",
        "# Calcola le metriche per la classificazione\n",
        "accuracy_svm = accuracy_score(y_test, svm_pred)\n",
        "\n",
        "#Random Forest\n",
        "# Importa il modello migliore \n",
        "best_rf_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_rf_model.pkl\")\n",
        "# Addestramento dei con tutti i dati di addestramento\n",
        "best_rf_model.fit(X_train, np.ravel(y_train))\n",
        "# Salva le metriche di valutazione del modello migliore di Random Forest\n",
        "evaluate_model(X_test, y_test, \"RF\", best_rf_model)\n",
        "rf_pred=best_rf_model.predict(X_test)\n",
        "# Calcola le metriche per la classificazione\n",
        "accuracy_rf = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "#Importa il modello migliore \n",
        "best_lr_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_lr_model.pkl\")\n",
        "# Addestramento dei con tutti i dati di addestramento\n",
        "best_lr_model.fit(X_train,np.ravel(y_train))\n",
        "# Salva le metriche di valutazione del modello migliore di Logistic Regression\n",
        "evaluate_model(X_test, y_test, \"Logistic Regression\", best_lr_model)\n",
        "lr_pred=best_lr_model.predict(X_test)\n",
        "# Calcola le metriche per la classificazione\n",
        "accuracy_lr = accuracy_score(y_test, lr_pred)\n",
        "\n",
        "#Naive Bayes\n",
        "# Importa il modello migliore \n",
        "best_nb_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_nb_model.pkl\")\n",
        "# Addestramento dei con tutti i dati di addestramento\n",
        "best_nb_model.fit(X_train,np.ravel(y_train))\n",
        "# Salva le metriche di valutazione del miglior modello Naive Bayes Classifier\n",
        "evaluate_model(X_test, y_test, \"Naive Bayes\", best_nb_model)\n",
        "nb_pred=best_nb_model.predict(X_test)\n",
        "# Calcola le metriche per la classificazione\n",
        "accuracy_nb = accuracy_score(y_test, nb_pred)\n",
        "\n",
        "#AdaBoost\n",
        "#Importa il modello migliore \n",
        "best_ab_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_adaboost_model.pkl\")\n",
        "# Addestramento dei con tutti i dati di addestramento\n",
        "best_ab_model.fit(X_train,np.ravel(y_train))\n",
        "# Salva le metriche di valutazione del miglior modello Naive Bayes Classifier\n",
        "evaluate_model(X_test, y_test, \"AdaBoostr\", best_ab_model)\n",
        "ab_pred=best_nb_model.predict(X_test)\n",
        "# Calcola le metriche per la classificazione\n",
        "accuracy_ab = accuracy_score(y_test, nb_pred)\n",
        "\n",
        "# Stampa delle accuratezze\n",
        "print(\"Accuratezza XGBOOST:\", accuracy_xgboost)\n",
        "print(\"Accuratezza SMV:\", accuracy_svm)\n",
        "print(\"Accuratezza Random Forest:\", accuracy_rf)\n",
        "print(\"Accuratezza Logistic Regression:\", accuracy_lr)\n",
        "print(\"Accuratezza Naive Bayes:\", accuracy_nb)\n",
        "print(\"Accuratezza AdaBoost:\", accuracy_ab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGbWtTZdB27d",
        "outputId": "1b6b5b72-8602-4767-e98d-056cf895ca24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuratezza XGBOOST: 0.8425925925925926\n",
            "Accuratezza SMV: 0.8009259259259259\n",
            "Accuratezza Random Forest: 0.8379629629629629\n",
            "Accuratezza Logistic Regression: 0.8148148148148148\n",
            "Accuratezza Naive Bayes: 0.6342592592592593\n",
            "Accuratezza AdaBoost: 0.6342592592592593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Requirements**"
      ],
      "metadata": {
        "id": "9bxZIkRByFSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Comando necessario per ottenere le librerie installate insieme alle loro versioni specifiche.\n",
        "import subprocess\n",
        "path = '/content/drive/Shareddrives/biometria_progetto/requirements_SB.txt'\n",
        "subprocess.run(f'pip freeze > {path}', shell=True, check=True)"
      ],
      "metadata": {
        "id": "T_5_vPd_yK2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00bab997-a1a6-4bea-8df9-28e33e9fb9ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='pip freeze > /content/drive/Shareddrives/biometria_progetto/requirements_SB.txt', returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}