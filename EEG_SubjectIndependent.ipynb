{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxoL219icBu1"
      },
      "source": [
        "## **Collegamento Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C96FHlUUDlRA",
        "outputId": "4d031346-afd8-4e25-d91e-a443c563fcfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH3rDLJEZKXh"
      },
      "source": [
        "# **Valutazione Modelli**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh3uNvfq-OJx"
      },
      "source": [
        "## **Import librerie**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zDwL0LYpK1Rn"
      },
      "outputs": [],
      "source": [
        "#utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#modelli\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRYA4G-8fruZ"
      },
      "source": [
        "## Import dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n_tBN148rGtd"
      },
      "outputs": [],
      "source": [
        "#Import dati combinati\n",
        "data_combined = pd.read_csv('/content/drive/Shareddrives/biometria_progetto/combinated_data.csv')\n",
        "keystotal = data_combined['Key']\n",
        "data_combined2 = data_combined.drop(['Key'], axis=1)\n",
        "\n",
        "#Rimozione dei valori nulli\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "dati_imputed = pd.DataFrame(imputer.fit_transform(data_combined2), columns=data_combined2.columns)\n",
        "\n",
        "#Normalizzazione dei dati\n",
        "normalised_data = pd.DataFrame(normalize(dati_imputed, axis = 0))\n",
        "normalised_data['Key']= keystotal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYP0NgZoSrLQ"
      },
      "source": [
        "# **EVALUATE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sVK4gVnASvth"
      },
      "outputs": [],
      "source": [
        "#Valutazione dei modelli\n",
        "def evaluate_model(X_test, y_test, model_name, model):\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # Calcolare la precisione, il richiamo e l'F1-score\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    \n",
        "    # Crea un DataFrame con i risultati\n",
        "    results = pd.DataFrame({'Model': [model_name],\n",
        "                            'Accuracy': [accuracy],\n",
        "                            'Precision': [precision],\n",
        "                            'Recall': [recall],\n",
        "                            'F1-score': [f1]})\n",
        "    \n",
        "    # Salva i risultati in un file CSV\n",
        "    results.to_csv('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectIndipendent/Metriche_modelli/'+model_name+'_metrics_results.csv', index=False)\n",
        "\n",
        "    # Calcolare la matrice di confusione normalizzata\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Creare una figura per la matrice di confusione\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Plotting della matrice di confusione normalizzata utilizzando una heatmap\n",
        "    sns.heatmap(cm_normalized, annot=True, cmap=plt.cm.Blues)\n",
        "\n",
        "    # Impostazione dei titoli degli assi\n",
        "    plt.title(model_name + ' Confusion Matrix')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "\n",
        "    # Salva la matrice di confusione come un file PDF\n",
        "    plt.savefig('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectIndipendent/Matrici_di_confusione/' + model_name + '_confusion_matrix.pdf', format='pdf', bbox_inches='tight')\n",
        "\n",
        "    # Chiude la figura\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbOXO4ZgoA-h"
      },
      "source": [
        "# **MAIN** (Subject Indipendent con Leave-One-Subject-Out-Cross-Validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k6wxl9eB077k"
      },
      "outputs": [],
      "source": [
        "# Caricamento delle etichette da un file CSV\n",
        "etichette_train =pd.read_csv('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectIndipendent/etichettetrain.csv')\n",
        "etichette_test = pd.read_csv('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectIndipendent/etichettetest.csv')\n",
        "\n",
        "# Lista dei partecipanti\n",
        "lista_partecipanti = [\"ldy\", \"rx\", \"qyt\", \"tyc\", \"ha\", \"whh\", \"mz\", \"mhw\", \"zjy\", \"wll\" ,\"zjd\", \"hql\", \"ly\", \"wq\", \"cz\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDbSDZD-x4ny"
      },
      "source": [
        "## **XGBOOST**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gestione del warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.metrics\")"
      ],
      "metadata": {
        "id": "qZcoqISgoYN0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Siv-Cqybx93r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f51d453-973b-42df-8714-94aa87817200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza XGBOOST: 0.9131172839506174\n"
          ]
        }
      ],
      "source": [
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_xgboost= 0.0\n",
        "media_xgboost= 0.0\n",
        "accuracyfinalxgboost= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    X_testd  = data[data['Key'].str.contains(partecipante)]\n",
        "    X_traind = data[~data['Key'].str.contains(partecipante)]\n",
        "\n",
        "    X_train = X_traind.drop(['Key'], axis=1)\n",
        "    X_test =X_testd.drop(['Key'], axis=1)\n",
        "      \n",
        "    # Importa il modello migliore di xgboost\n",
        "    best_xgboost_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_xgboost_model.pkl\")\n",
        "    \n",
        "    # Salva le metriche di valutazione del modello \n",
        "    evaluate_model(X_test, etichette_test, \"XGBoost\",best_xgboost_model)\n",
        "\n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_xgboost_model.fit(X_train, np.ravel(etichette_train))\n",
        "\n",
        "    xgboost_pred = best_xgboost_model.predict(X_test)\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_xgboost = accuracy_score(etichette_test, xgboost_pred)\n",
        "    \n",
        "    #Aggiornamento dell'accuratezza totale\n",
        "    acc_xgboost += accuracy_xgboost\n",
        "    iterazioni += 1\n",
        "      \n",
        "  # Calcolo della media per ogni sessione\n",
        "  media_xgboost = acc_xgboost / iterazioni\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalxgboost += media_xgboost\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza XGBOOST:\", accuracyfinalxgboost/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b3nf9iByoLB"
      },
      "source": [
        "## **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PUdQZPebymuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9e9e42-21a0-43ed-bf44-05c881840e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza SMV: 0.8966049382716049\n"
          ]
        }
      ],
      "source": [
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_svm= 0.0\n",
        "media_svm= 0.0\n",
        "accuracyfinalvsm= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    X_testd  = data[data['Key'].str.contains(partecipante)]\n",
        "    X_traind = data[~data['Key'].str.contains(partecipante)]\n",
        "\n",
        "    X_train = X_traind.drop(['Key'], axis=1)\n",
        "    X_test =X_testd.drop(['Key'], axis=1)\n",
        "      \n",
        "    # Importa il modello migliore di xgboost\n",
        "    best_svm_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_svm_model.pkl\")\n",
        "\n",
        "    # Salva le metriche di valutazione del modello \n",
        "    evaluate_model(X_test, etichette_test, \"SVM\", best_svm_model)\n",
        "  \n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_svm_model.fit(X_train, np.ravel(etichette_train))\n",
        "   \n",
        "    svm_pred= best_svm_model.predict(X_test)\n",
        "  \n",
        "    #Calcola le metriche per la classificazione\n",
        "    accuracy_svm = accuracy_score(etichette_test, svm_pred)\n",
        "\n",
        "    #Aggiornamento dell'accuratezza totale\n",
        "    acc_svm += accuracy_svm\n",
        "    iterazioni += 1\n",
        "      \n",
        "  # Calcolo della media per ogni sessione\n",
        "  media_svm = acc_svm / iterazioni\n",
        "\n",
        "  #Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalvsm += media_svm\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza SMV:\", accuracyfinalvsm/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX8cLub-z5Ag"
      },
      "source": [
        "## **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vUzA0kr2zY98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388dce7d-279a-44ba-fd1a-b0dacca3b42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza Random Forest: 0.9216049382716051\n"
          ]
        }
      ],
      "source": [
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_rf= 0.0\n",
        "media_rf= 0.0\n",
        "accuracyfinalrf= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    X_testd  = data[data['Key'].str.contains(partecipante)]\n",
        "    X_traind = data[~data['Key'].str.contains(partecipante)]\n",
        "\n",
        "    X_train = X_traind.drop(['Key'], axis=1)\n",
        "    X_test =X_testd.drop(['Key'], axis=1)\n",
        "      \n",
        "    # Importa il modello migliore di xgboost\n",
        "    best_rf_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_rf_model.pkl\")\n",
        "\n",
        "    # Salva le metriche di valutazione del modello migliore di Random Forest\n",
        "    evaluate_model(X_test, etichette_test, \"RF\", best_rf_model)\n",
        "   \n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_rf_model.fit(X_train, np.ravel(etichette_train))\n",
        "\n",
        "    rf_pred=best_rf_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_rf = accuracy_score(etichette_test, rf_pred)\n",
        " \n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_rf += accuracy_rf\n",
        "    iterazioni += 1\n",
        "      \n",
        "  # Calcolo della media per ogni sessione\n",
        "  media_rf = acc_rf / iterazioni\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalrf +=media_rf\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza Random Forest:\", accuracyfinalrf/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression**"
      ],
      "metadata": {
        "id": "84CS68BeqPxD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "U_2OIqdX0QDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b056a6-aa41-473f-b2f2-fa92893b1814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza Logistic Regression: 0.917283950617284\n"
          ]
        }
      ],
      "source": [
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_lr= 0.0\n",
        "media_lr= 0.0\n",
        "accuracyfinallr= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    X_testd  = data[data['Key'].str.contains(partecipante)]\n",
        "    X_traind = data[~data['Key'].str.contains(partecipante)]\n",
        "\n",
        "    X_train = X_traind.drop(['Key'], axis=1)\n",
        "    X_test =X_testd.drop(['Key'], axis=1)\n",
        "      \n",
        "    # Importa il modello migliore di xgboost\n",
        "    best_lr_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_lr_model.pkl\")\n",
        "\n",
        "    # Salva le metriche di valutazione del modello migliore di Logistic Regression\n",
        "    evaluate_model(X_test, etichette_test, \"Logistic Regression\", best_lr_model)\n",
        "\n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_lr_model.fit(X_train,np.ravel(etichette_train))\n",
        "\n",
        "    lr_pred=best_lr_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_lr = accuracy_score(etichette_test, lr_pred)\n",
        "\n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_lr += accuracy_lr\n",
        "    iterazioni += 1\n",
        "      \n",
        "  # Calcolo della media per ogni sessione\n",
        "  media_lr = acc_lr / iterazioni\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinallr +=media_lr\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza Logistic Regression:\", accuracyfinallr/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XQ7u5zx0nIR"
      },
      "source": [
        "## **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_smOQSMp0tEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db8e64f-0779-44ec-a893-15e7c353739e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza Naive Bayes: 0.8574074074074076\n"
          ]
        }
      ],
      "source": [
        "#Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_nb= 0.0\n",
        "media_nb= 0.0\n",
        "accuracyfinalnb= 0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    X_testd  = data[data['Key'].str.contains(partecipante)]\n",
        "    X_traind = data[~data['Key'].str.contains(partecipante)]\n",
        "\n",
        "    X_train = X_traind.drop(['Key'], axis=1)\n",
        "    X_test =X_testd.drop(['Key'], axis=1)\n",
        "      \n",
        "    # Importa il modello migliore di xgboost\n",
        "    best_nb_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_nb_model.pkl\")\n",
        "\n",
        "    # Salva le metriche di valutazione del miglior modello Naive Bayes Classifier\n",
        "    evaluate_model(X_test, etichette_test, \"Naive Bayes\", best_nb_model)\n",
        "   \n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_nb_model.fit(X_train,np.ravel(etichette_train))\n",
        "\n",
        "    nb_pred=best_nb_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_nb = accuracy_score(etichette_test, nb_pred)\n",
        "\n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_nb += accuracy_nb\n",
        "    iterazioni += 1\n",
        "      \n",
        "  # Calcolo della media per ogni sessione\n",
        "  media_nb = acc_nb / iterazioni\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalnb +=media_nb\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza Naive Bayes:\", accuracyfinalnb/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPBJJ4oF1ciX"
      },
      "source": [
        "## **AdaBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1PRIoMVA1htt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbe3d30-62d8-4b51-e2ab-0c0148660fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media dell'accuratezza AdaBoost: 0.8574074074074076\n"
          ]
        }
      ],
      "source": [
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_ab = 0.0\n",
        "media_ab  =0.0\n",
        "accuracyfinalab=0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=normalised_data[normalised_data['Key'].str.contains(f\"{i}_\")]\n",
        "    X_testd  = data[data['Key'].str.contains(partecipante)]\n",
        "    X_traind = data[~data['Key'].str.contains(partecipante)]\n",
        "\n",
        "    X_train = X_traind.drop(['Key'], axis=1)\n",
        "    X_test =X_testd.drop(['Key'], axis=1)\n",
        "      \n",
        "    # Importa il modello migliore di xgboost\n",
        "    best_ab_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_adaboost_model.pkl\")\n",
        "\n",
        "    # Salva le metriche di valutazione del miglior modello Naive Bayes Classifier\n",
        "    evaluate_model(X_test, etichette_test, \"AdaBoostr\", best_ab_model)\n",
        "   \n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_ab_model.fit(X_train,np.ravel(etichette_train))\n",
        "\n",
        "    ab_pred=best_ab_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_ab = accuracy_score(etichette_test, nb_pred)\n",
        "  \n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_ab += accuracy_ab\n",
        "    iterazioni += 1\n",
        "      \n",
        "  # Calcolo della media per ogni sessione\n",
        "  media_ab = acc_ab / iterazioni\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalab +=media_ab\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza AdaBoost:\", accuracyfinalnb/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy0uDWdJyFZZ"
      },
      "source": [
        "## **Codice completo con tutti e 6 i modelli**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD5g4h2IFCxi"
      },
      "outputs": [],
      "source": [
        "'''# Caricamento delle etichette da un file CSV\n",
        "etichette_train =pd.read_csv('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectIndipendent/etichettetrain.csv')\n",
        "etichette_test = pd.read_csv('/content/drive/Shareddrives/biometria_progetto/materiale_SubjectIndipendent/etichettetest.csv')\n",
        "\n",
        "# Inizializzazione delle variabili per calcolare la media dell'accuratezza\n",
        "acc_xgboost,acc_svm,acc_rf,acc_lr,acc_nb,acc_ab = 0.0,0.0,0.0,0.0,0.0,0.0\n",
        "media_xgboost,media_svm,media_rf,media_lr,media_nb,media_ab  =0.0,0.0,0.0,0.0,0.0,0.0\n",
        "accuracyfinalxgboost,accuracyfinalvsm,accuracyfinalrf,accuracyfinallr,accuracyfinalnb,accuracyfinalab=0.0,0.0,0.0,0.0,0.0,0.0\n",
        "iterazioni = 0.0\n",
        "\n",
        "# Lista dei partecipanti\n",
        "lista_partecipanti = [\"ldy\", \"rx\", \"qyt\", \"tyc\", \"ha\", \"whh\", \"mz\", \"mhw\", \"zjy\", \"wll\" ,\"zjd\", \"hql\", \"ly\", \"wq\", \"cz\"]\n",
        "\n",
        "#per ogni sessione\n",
        "for i in range(1, 4):\n",
        "  # Iterazione per chiave del dizionario\n",
        "  for partecipante in lista_partecipanti:\n",
        "    # Separare i dati di addestramento e di test\n",
        "    data=dati_imputed[dati_imputed['Key'].str.contains(f\"{i}_\")]\n",
        "    X_testd  = data[data['Key'].str.contains(partecipante)]\n",
        "    X_traind = data[~data['Key'].str.contains(partecipante)]\n",
        "\n",
        "    X_train = X_traind.drop(['Key'], axis=1)\n",
        "    X_test =X_testd.drop(['Key'], axis=1)\n",
        "      \n",
        "    # Importa il modello migliore di xgboost\n",
        "    best_xgboost_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_xgboost_model.pkl\")\n",
        "    best_svm_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_svm_model.pkl\")\n",
        "    best_rf_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_rf_model.pkl\")\n",
        "    best_lr_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_lr_model.pkl\")\n",
        "    best_nb_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_nb_model.pkl\")\n",
        "    best_ab_model = joblib.load(\"/content/drive/Shareddrives/biometria_progetto/materiale_SubjectBiased/Modelli/best_adaboost_model.pkl\")\n",
        "   \n",
        "    # Addestramento dei con tutti i dati di addestramento\n",
        "    best_xgboost_model.fit(X_train, np.ravel(etichette_train))\n",
        "    best_svm_model.fit(X_train, np.ravel(etichette_train))\n",
        "    best_rf_model.fit(X_train, np.ravel(etichette_train))\n",
        "    best_lr_model.fit(X_train,np.ravel(etichette_train))\n",
        "    best_nb_model.fit(X_train,np.ravel(etichette_train))\n",
        "    best_ab_model.fit(X_train,np.ravel(etichette_train))\n",
        "\n",
        "    xgboost_pred = best_xgboost_model.predict(X_test)\n",
        "    svm_pred= best_svm_model.predict(X_test)\n",
        "    rf_pred=best_rf_model.predict(X_test)\n",
        "    lr_pred=best_lr_model.predict(X_test)\n",
        "    nb_pred=best_nb_model.predict(X_test)\n",
        "    ab_pred=best_ab_model.predict(X_test)\n",
        "\n",
        "    # Calcola le metriche per la classificazione\n",
        "    accuracy_xgboost = accuracy_score(etichette_test, xgboost_pred)\n",
        "    accuracy_svm = accuracy_score(etichette_test, svm_pred)\n",
        "    accuracy_rf = accuracy_score(etichette_test, rf_pred)\n",
        "    accuracy_lr = accuracy_score(etichette_test, lr_pred)\n",
        "    accuracy_nb = accuracy_score(etichette_test, nb_pred)\n",
        "    accuracy_ab = accuracy_score(etichette_test, nb_pred)\n",
        "  \n",
        "    # Aggiornamento dell'accuratezza totale\n",
        "    acc_xgboost += accuracy_xgboost\n",
        "    acc_svm += accuracy_svm\n",
        "    acc_rf += accuracy_rf\n",
        "    acc_lr += accuracy_lr\n",
        "    acc_nb += accuracy_nb\n",
        "    acc_ab += accuracy_ab\n",
        "    iterazioni += 1\n",
        "      \n",
        "  # Calcolo della media per ogni sessione\n",
        "  media_xgboost = acc_xgboost / iterazioni\n",
        "  media_svm = acc_svm / iterazioni\n",
        "  media_rf = acc_rf / iterazioni\n",
        "  media_lr = acc_lr / iterazioni\n",
        "  media_nb = acc_nb / iterazioni\n",
        "  media_ab = acc_ab / iterazioni\n",
        "\n",
        "  # Calcolo della media tra le 3 sessioni\n",
        "  accuracyfinalxgboost += media_xgboost\n",
        "  accuracyfinalvsm += media_svm\n",
        "  accuracyfinalrf +=media_rf\n",
        "  accuracyfinallr +=media_lr\n",
        "  accuracyfinalnb +=media_nb\n",
        "  accuracyfinalab +=media_ab\n",
        "\n",
        "# Stampa della media dell'accuratezza\n",
        "print(\"Media dell'accuratezza XGBOOST:\", accuracyfinalxgboost/3)\n",
        "print(\"Media dell'accuratezza SMV:\", accuracyfinalvsm/3)\n",
        "print(\"Media dell'accuratezza RF:\", accuracyfinalrf/3)\n",
        "print(\"Media dell'accuratezza LR:\", accuracyfinallr/3)\n",
        "print(\"Media dell'accuratezza NB:\", accuracyfinalnb/3)\n",
        "print(\"Media dell'accuratezza AB:\", accuracyfinalnb/3)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9m49RGtyrdW"
      },
      "source": [
        "# **Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GFf1qb-7ytke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d7b356-818c-4dc0-8ebd-f827f67dbee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='pip freeze > /content/drive/Shareddrives/biometria_progetto/requirements_SI.txt', returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#Comando necessario per ottenere le librerie installate insieme alle loro versioni specifiche.\n",
        "import subprocess\n",
        "path = '/content/drive/Shareddrives/biometria_progetto/requirements_SI.txt'\n",
        "subprocess.run(f'pip freeze > {path}', shell=True, check=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}